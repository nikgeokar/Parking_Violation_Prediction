{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this Notebook I convert the data of the scans I created in the Scans_Data_Processing file to be suitable for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Proccesing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "Project_Path='Local Path'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I load the Scans_Data2 file I created into the Scans_Data_Processing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scans_Data=pd.read_csv(Project_Path+ '/Data/Scan_Data2.csv',low_memory=False,sep=',',index_col=0)\n",
    "Scans_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am converting the format of the \"Date\" column from \"Year/Month/Day\" to \"Month/Day/Year\" so that it has the appropriate format so that I can then convert it to pandas datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Date_List=[]\n",
    "Scans_List=Scans_Data.values.tolist()\n",
    "for i in tqdm(range(0,len(Scans_List))):\n",
    "    Date = Scans_List[i][0]\n",
    "    y,m,d = Date.split('-')\n",
    "    D=m + '/' + d + '/' +y\n",
    "    Date_List.append(D)\n",
    "Scans_Data=Scans_Data.drop(['Date'], axis=1)\n",
    "Scans_Data.insert(1, \"Date\", Date_List, True)\n",
    "Scans_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μετατρέπω τις στήλες 'Date' και 'Time' σε pandas datetime ώστε να μετατρέψω την ώρα σε time-int (Seconds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scans_Data['Date_Time'] = Scans_Data['Date'].map(str)+ ' ' + Scans_Data['Time'].map(str)\n",
    "Scans_Data['Date_Time'] = pd.to_datetime(Scans_Data['Date_Time'])\n",
    "Scans_Data['Time_Int'] = (Scans_Data['Date_Time']-Scans_Data['Date_Time'].dt.normalize()).dt.total_seconds()\n",
    "Scans_Data=Scans_Data.drop(['Time'], axis=1)\n",
    "Scans_Data=Scans_Data.drop(['Date_Time'], axis=1)\n",
    "Scans_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing from the previous notebook what are the times when I have recorded scans (6:00, 7:00,..., 19:00, 20:00) I give their imprint in seconds, for example (6:00 = 21600) and then I capture her with their center. eg (6:00 -> 6:30) and therefore (21600->23400). So I ended up with a list of 15 hours that will be used to sort the scans into time slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_Slots=[21600,25200,28800,32400,36000,39600,43200,46800,50400,54000,57600,61200,64800,68400,72000]\n",
    "Time_SlotsCenter=[]\n",
    "for i in range (0,len(Time_Slots)):\n",
    "    Time_SlotsCenter.append(Time_Slots[i]+1800)\n",
    "Time_Slots=Time_SlotsCenter\n",
    "Time_Slots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above list I classified each scan in the time-slot that was closest. That is, a scan that was done at 12:45 went to the time-slot '12:00-13:00' which is captured as 12:00. That is, I added the Time_Slot column. I also added the Time_Distance column which states how far in seconds the pre-wedding time of the scan is from the center of the timeslot we ranked the scan. I use Time_Distance to check for ranking errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scan_List=Scans_Data.values.tolist()\n",
    "Real_Time_Slots=[]\n",
    "Time_Distance=[]\n",
    "for i in tqdm(range(0,len(Scan_List))):\n",
    "    Real_Time=Scan_List[i][12]\n",
    "    Distances=[]\n",
    "    Slots=[]\n",
    "    \n",
    "    for j in range (0,len(Time_Slots)):\n",
    "        Distances.append(abs(Time_Slots[j]-Real_Time))\n",
    "        \n",
    "    Slots=np.column_stack((Time_Slots, Distances))\n",
    "    Slots = sorted(Slots, key=lambda x: x[1])\n",
    "    Real_Time_Slots.append(Slots[0][0])\n",
    "    Time_Distance.append(Slots[0][1])\n",
    "Scans_Data.insert(13, \"Time_Slot\", Real_Time_Slots, True)   \n",
    "Scans_Data.insert(14, \"Time_Distance\", Time_Distance, True)   \n",
    "Scans_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I deleted the scans done during the lock down period. I explain in the report why I did this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scans_Data.drop(Scans_Data.index[Scans_Data['Lockdown'] == 1], inplace=True)\n",
    "Scans_Data=Scans_Data.reset_index()\n",
    "del Scans_Data[\"index\"]\n",
    "Scans_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I keep only the columns I need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scans_Data2=Scans_Data['Slot_id'],Scans_Data['Date'],Scans_Data['Day Name'], Scans_Data['Time_Int'], Scans_Data['Time_Slot'],Scans_Data['Covid'],Scans_Data['Legal']\n",
    "Headers=['Slot_id','Date','Day Name','Time_Int','Time_Slot','Covid','Legal']\n",
    "Scans_Data2 = pd.concat(Scans_Data2, axis=1, keys=Headers)\n",
    "Scans_Data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I convert the Legal column to categorical to then do one-hot encoding. (This step is unnecessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scans_Data2['Legal'] = Scans_Data2['Legal'].replace(1, 'Legal')\n",
    "Scans_Data2['Legal'] = Scans_Data2['Legal'].replace(0, 'Ilegal')\n",
    "Scans_Data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do one hot encoding of the legal column, create 2 new columns through this process and delete the legal column. Then I save the dataframe to have this point as a check-point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating initial dataframe\n",
    "Legality_Types = ('Legal','Ilegal')\n",
    "Legaldf = pd.DataFrame(Scans_Data2, columns=['Legal'])\n",
    "# generate binary values using get_dummies\n",
    "Legality = pd.get_dummies(Legaldf, columns=[\"Legal\"], prefix=[\"Legality\"] )\n",
    "# merge with main df bridge_df on key values\n",
    "Scans_Data2 = Scans_Data2.join(Legality)\n",
    "Scans_Data2=Scans_Data2.drop(['Legal'], axis=1)\n",
    "Scans_Data2.to_csv(Project_Path+ '/Data/Scan_Data_Reg_2.1.csv')\n",
    "Scans_Data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I convert some of the columns into a string that will be used as a key. I leave out the column specifying the actual time of each scan and the columns specifying the parking violation. The key contains information about the time domain, the time-slot. So samples with the same key are scans made on the same day in the same time-slot in the same sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scans_Data2=pd.read_csv(Project_Path+ '/Data/Scan_Data_Reg_2.1.csv',low_memory=False,sep=',',index_col=0)\n",
    "Scans_Data2['Key'] = Scans_Data2['Slot_id'].map(str)+ '+' +Scans_Data2['Date'].map(str) + '+' + Scans_Data2['Day Name'].map(str)+ '+' + Scans_Data2['Time_Slot'].map(str)+ '+'+Scans_Data2['Covid'].map(str)\n",
    "Scans_Data2=Scans_Data2['Key'],Scans_Data2['Time_Int'],Scans_Data2['Legality_Ilegal'],Scans_Data2['Legality_Legal']\n",
    "Headers=['Key','Time_Int','Legality_Ilegal','Legality_Legal']\n",
    "Scans_Data2 = pd.concat(Scans_Data2, axis=1, keys=Headers)\n",
    "Scans_Data2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I group by and for each different key I calculate the average time of the scans, the scans that showed illegality and the scans that showed legitimacy. Essentially with this process I collect the scans to create the controls, a control consists of scans done on the same day in the same time-slot in the same sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Time_Int = Scans_Data2.groupby([\"Key\"]).Time_Int.mean().reset_index()\n",
    "ILegal_Sum = Scans_Data2.groupby([\"Key\"]).Legality_Ilegal.sum().reset_index()\n",
    "Legal_Sum= Scans_Data2.groupby([\"Key\"]).Legality_Legal.sum().reset_index()\n",
    "Legal_Sum=Legal_Sum['Key'],Time_Int['Time_Int'],ILegal_Sum['Legality_Ilegal'],Legal_Sum['Legality_Legal']\n",
    "Headers=['Key','Time_Int','Legality_Ilegal','Legality_Legal']\n",
    "Legal_illegal = pd.concat(Legal_Sum, axis=1, keys=Headers)\n",
    "Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I calculate how many scans I got on each check and put it in the sum column then delete all the checks that resulted from 1 or two scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Legal_illegal['Sum']=Legal_illegal['Legality_Ilegal']+Legal_illegal['Legality_Legal']\n",
    "Legal_illegal.drop(Legal_illegal[Legal_illegal.Sum <= 2].index, inplace=True)\n",
    "Legal_illegal=Legal_illegal.reset_index()\n",
    "del Legal_illegal[\"index\"]\n",
    "Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I calculate for each scan the violation rate with the formula -> Rate = Illegal Scans/Total Scans. I also explain in the report in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scan_List2=Legal_illegal.values.tolist()\n",
    "Ilegality_Rate=[]\n",
    "for i in range (0,len(Scan_List2)):\n",
    "    if Scan_List2[i][2]==0:\n",
    "        Ilegality_Rate.append(0)\n",
    "    else:\n",
    "        Ilegality_Rate.append(Scan_List2[i][2]/(Scan_List2[i][2]+Scan_List2[i][3]))\n",
    "Legal_illegal.insert(3, \"Ilegality_Rate\", Ilegality_Rate, True)\n",
    "Legal_illegal=Legal_illegal.drop(['Legality_Ilegal'], axis=1)\n",
    "Legal_illegal=Legal_illegal.drop(['Legality_Legal'], axis=1)\n",
    "Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again I split the string key to create the original columns that made it up (This group by process is also done in a simpler way without having to make the string columns and then make the string columns but when I did it I didn't know which is also done in a faster way with pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scan_List2=Legal_illegal.values.tolist()\n",
    "Slot_id=[]\n",
    "Date=[]\n",
    "Day_Name=[]\n",
    "Slot_Timeint=[]\n",
    "Covid=[]\n",
    "for i in tqdm(range(0,len(Scan_List2))):\n",
    "    Slot_id_Value,Date_Value,Day_Name_Value,Slot_Timeint_Value,Covid_Value=Scan_List2[i][0].split('+')\n",
    "    Slot_id.append(Slot_id_Value)\n",
    "    Date.append(Date_Value)\n",
    "    Day_Name.append(Day_Name_Value)\n",
    "    Slot_Timeint.append(Slot_Timeint_Value)\n",
    "    Covid.append(Covid_Value)\n",
    "Legal_illegal.insert(1, \"Slot_id\", Slot_id, True)\n",
    "Legal_illegal.insert(2, \"Date\", Date, True)\n",
    "Legal_illegal.insert(3, \"Day_Name\",  Day_Name, True)\n",
    "Legal_illegal.insert(4, \"Slot_Timeint\", Slot_Timeint, True)\n",
    "Legal_illegal.insert(5, \"Covid\", Covid, True)\n",
    "Legal_illegal=Legal_illegal.drop(['Key'], axis=1)\n",
    "Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am converting the formats of some columns so that they are not strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Legal_illegal['Slot_Timeint'] = Legal_illegal['Slot_Timeint'].astype(float)\n",
    "Legal_illegal['Time_Int'] = Legal_illegal['Time_Int'].astype(float)\n",
    "Legal_illegal['Slot_Timeint'] = Legal_illegal['Slot_Timeint'].astype(int)\n",
    "Legal_illegal['Time_Int'] = Legal_illegal['Time_Int'].astype(int)\n",
    "Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I load the file that describes the domains, and according to that I create a column in the data set that describes the capacity in places of the domain that each control refers to. (And this is done more easily with merge than pandas, but when I wrote this file I didn't know how to work with pandas to the point where I knew these functions were there ready-made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Column_Names=['Slot_id','Adress','Mean','Start','End','Capacity','Full_adress','Latitude','Longitude']\n",
    "\n",
    "Parking_Slots2=pd.read_csv(Project_Path+ '/Data/Parkink_Slot_Proccesed.csv',sep=',', names=Column_Names)\n",
    "\n",
    "Parking_Slots2=Parking_Slots2.values.tolist()\n",
    "Scans_List2=Legal_illegal.values.tolist()\n",
    "Capacity=[]\n",
    "for i in tqdm(range(0,len(Scans_List2))):\n",
    "    for j in range (0,len(Parking_Slots2)):\n",
    "        if int(Parking_Slots2[j][0])==int(Scans_List2[i][0]):\n",
    "            c=int(Parking_Slots2[j][5])\n",
    "            Capacity.append(c) \n",
    "\n",
    "\n",
    "\n",
    "Legal_illegal.insert(7, \"Capacity\",Capacity, True)\n",
    "Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the number of scans made in each domain and according to the capacity of the domain, I create the column Attention which describes to what percentage the domain was checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scan_List2=Legal_illegal.values.tolist()\n",
    "Attention=[]\n",
    "for i in range (0,len(Scan_List2)):\n",
    "    if Scan_List2[i][8]>Scan_List2[i][7]:\n",
    "        Attention.append(1)\n",
    "    else:\n",
    "        Attention.append(Scan_List2[i][8]/(Scan_List2[i][7]))\n",
    "Legal_illegal.insert(7, \"Attention\", Attention, True)\n",
    "\n",
    "Legal_illegal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete audits where less than 20% of each domain was audited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Legal_illegal.drop(Legal_illegal[Legal_illegal.Attention <= 0.2].index, inplace=True)\n",
    "Legal_illegal.to_csv(Project_Path+ '/Data/Scan_Data_For_Analysis.csv')\n",
    "Legal_illegal=Legal_illegal.drop(['Attention'], axis=1)\n",
    "Legal_illegal=Legal_illegal.reset_index()\n",
    "del Legal_illegal[\"index\"]\n",
    "Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I load the file that describes the public holidays and create a column based on it that describes in a binary way whether the check was made on a public holiday or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Holidays= pd.read_csv(Project_Path+ '/Data/Holidays.txt', header = None,names=['Holidays'])\n",
    "Holidays_List=Holidays.values.tolist()\n",
    "Scan_List2=Legal_illegal.values.tolist()\n",
    "Holidays=[]\n",
    "for i in tqdm(range(0,len(Scan_List2))):\n",
    "    Boulean=False\n",
    "    for j in range (0,len(Holidays_List)):\n",
    "        if Scan_List2[i][1]==Holidays_List[j][0]:\n",
    "            Boulean=True\n",
    "    \n",
    "    if Boulean:\n",
    "        Holidays.append(1)\n",
    "    else:\n",
    "        Holidays.append(0)\n",
    "        \n",
    "Legal_illegal.insert(7, \"Holidays\", Holidays, True)\n",
    "Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I parse the Date column into: days of the month, month, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scan_List2=Legal_illegal.values.tolist()\n",
    "\n",
    "Date=[]\n",
    "Year=[]\n",
    "Mounth=[]\n",
    "Key_Date=[]\n",
    "\n",
    "for i in tqdm(range(0,len(Scan_List2))):\n",
    "    m,d,y=Scan_List2[i][1].split('/')\n",
    "    Mounth.append(int(m))\n",
    "    Date.append(int(d))\n",
    "    Year.append(int(y))\n",
    "    D=y + '-' + m + '-' +d\n",
    "    Key_Date.append(D)\n",
    "\n",
    "Legal_illegal.insert(1, \"Key_Date\", Key_Date, True)\n",
    "Legal_illegal.insert(2, \"Date_Of_Month\", Date, True)\n",
    "Legal_illegal.insert(3, \"Year\", Year, True)\n",
    "Legal_illegal.insert(4, \"Month\", Mounth, True)\n",
    "Legal_illegal=Legal_illegal.drop(['Date'], axis=1)\n",
    "Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I save the Dataframe as a csv so that I have this point as a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Legal_illegal.to_csv(Project_Path+ '/Data/Scan_Data_Reg_2.2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Legal_illegal=pd.read_csv(Project_Path+ '/Data/Scan_Data_Reg_2.2.csv',sep=',',index_col=0)\n",
    "Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I convert the days of the week into numbers, i.e. the second became 1 the third became 2 etc etc so that I can format it afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List=Legal_illegal.values.tolist()\n",
    "Week_Day=[]\n",
    "Legal_illegal=Legal_illegal.drop(['Day_Name'], axis=1)\n",
    "Day_Name_To_Day_Slot=[['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],[1,2,3,4,5,6,7]]\n",
    "for i in tqdm(range(0,len(List))):\n",
    "    for j in range(0,7):\n",
    "        if List[i][5]==Day_Name_To_Day_Slot[0][j]:\n",
    "            Week_Day.append(Day_Name_To_Day_Slot[1][j])\n",
    "   \n",
    "Legal_illegal.insert(2, \"Week_Day\", Week_Day, True)\n",
    "Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am converting the days of the week to semicolons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data, col, max_val):\n",
    "    data[col + '_Sin'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data\n",
    "Legal_illegal = encode(Legal_illegal, 'Week_Day', 7)\n",
    "Legal_illegal = encode(Legal_illegal, 'Month', 12)\n",
    "Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I convert the days of the month to sine and pay attention to how many days each month has. February was thought to always have 29 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List=Legal_illegal.values.tolist()\n",
    "Date_Sin=[]\n",
    "Month_Sin_Rules=[[1,2,3,4,5,6,7,8,9,10,11,12],[31,29,31,30,31,30,31,31,30,31,30,31]] #Κανόνες με τις μέρες που έχει ο κάθε μήνας\n",
    "for i in tqdm(range(0,len(List))):\n",
    "    for j in range(0,12):\n",
    "        if List[i][5]==Month_Sin_Rules[0][j]:\n",
    "            Max=Month_Sin_Rules[1][j]\n",
    "    sin=np.sin(2 * np.pi * List[i][2]/Max)\n",
    "    Date_Sin.append(sin)\n",
    "Legal_illegal.insert(2, \"Date_Sin\", Date_Sin, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I delete the columns that describe the month days etc. Since now I have columns that capture these features in sine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Legal_illegal=Legal_illegal.drop(['Week_Day'], axis=1)\n",
    "Legal_illegal=Legal_illegal.drop(['Month'], axis=1)\n",
    "Legal_illegal=Legal_illegal.drop(['Date_Of_Month'], axis=1)\n",
    "Legal_illegal=Legal_illegal.drop(['Sum'], axis=1)\n",
    "Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the date and time I create a column that I call key. The key column describes the date and time without describing the minutes of the time. I make it in this format because hourly temperatures from the weather data are also described in this format. So I create this column to merge with the weather data later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time=Legal_illegal['Slot_Timeint']/3600 #convert seconds to hours\n",
    "Time=Time.astype(int) #i only get the hour and not the minutes\n",
    "Time=Time.values.tolist()\n",
    "NewT=[]\n",
    "for i in range (0,len(Time)):\n",
    "    Str=str(Time[i])\n",
    "    if Time[i]>=10:\n",
    "        NewT.append(Str)\n",
    "    else:\n",
    "        NewT.append('0'+Str)\n",
    "\n",
    "\n",
    "Time=pd.DataFrame(NewT,columns=[\"Hour\"])\n",
    "\n",
    "\n",
    "Time= Time[\"Hour\"].map(str)+ ':00' \n",
    "Key_Weather=Legal_illegal['Key_Date'].map(str) + ' ' + Time\n",
    "Legal_illegal=Legal_illegal.drop(['Key_Date'], axis=1)\n",
    "Legal_illegal.insert(1, \"Key\", Key_Weather, True)\n",
    "Legal_illegal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I convert the columns that capture the timeslot and premarital time to be in the range 0-1 and delete the column that captures the time as I don't need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Legal_illegal['Slot_Timeint']=Legal_illegal['Slot_Timeint']/timedelta(days=1).total_seconds()\n",
    "Legal_illegal['Time_Int']=Legal_illegal['Time_Int']/timedelta(days=1).total_seconds()\n",
    "Legal_illegal=Legal_illegal.drop(['Year'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I save the DataFrame as 'Scan_Data_Reg_2.3.csv'. Where and this is the final file that will go on the notebook that I train the model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Legal_illegal.to_csv(Project_Path+ '/Data/Scan_Data_Reg_2.3.csv')\n",
    "Legal_illegal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
